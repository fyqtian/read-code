http://mysql.taobao.org/monthly/2015/12/01/ 事务子系统介绍

http://mysql.taobao.org/monthly/2015/04/01/ undo log 漫游

http://mysql.taobao.org/monthly/2015/06/01/ 崩溃过程

http://mysql.taobao.org/monthly/2015/05/01/   redo log漫游

http://mysql.taobao.org/monthly/2018/03/01/



https://segmentfault.com/a/1190000016566788?utm_source=tag-newest 事务



http://mysql.taobao.org/monthly/2017/12/01/

http://mysql.taobao.org/monthly/2014/12/01/

https://zhuanlan.zhihu.com/p/103580034?utm_source=wechat_session 幻读



https://blog.csdn.net/sanyuesan0000/article/details/90235335

https://www.cnblogs.com/f-ck-need-u/archive/2018/05/08/9010872.html



ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性

- 读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。
- 读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。
- 可重复读是指，**一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的**。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
- 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。

<img src="..\images\7dea45932a6b722eb069d2264d0066f8.png" alt="7dea45932a6b722eb069d2264d0066f8" style="zoom: 33%;" />



我们来看看在不同的隔离级别下，事务A会有哪些不同的返回结果，也就是图里面V1、V2、V3的返回值分别是什么。

- 若隔离级别是“读未提交”， 则V1的值就是2。这时候事务B虽然还没有提交，但是结果已经被A看到了。因此，V2、V3也都是2。
- 若隔离级别是“读提交”，则V1是1，V2的值是2。事务B的更新在提交后才能被A看到。所以， V3的值也是2。
- 若隔离级别是“可重复读”，则V1、V2是1，V3是2。之所以V2还是1，遵循的就是这个要求：**事务在执行期间看到的数据前后必须是一****致的**。
- 若隔离级别是“串行化”，则在事务B执行“将1改成2”的时候，会被锁住。直到事务A提交后，事务B才可以继续执行。所以从A的角度看， V1、V2值是1，V3的值是2。



在实现上，**数据库里面会创建一个视图**，访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，**这个视图是在事务启动时创建的，整个事务存在期间都用这个视图**。在“读提交”隔离级别下**，这个视图是在每个SQL语句开始执行的时候创建的**。这里需要注意的是，**“读未提交”隔离级别下直接返回记录上的最新值**，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。



# 事务隔离的实现

理解了事务的隔离级别，我们再来看看事务隔离具体是怎么实现的。这里我们展开说明“可重复读”。

在MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。

假设一个值从1被按顺序改成了2、3、4，在回滚日志里面就会有类似下面的记录。

<img src="..\images\d9c313809e5ac148fc39feff532f0fee.png"  style="zoom:67%;" />

​	当前值是4，但是在查询这条记录的时候，**不同时刻启动的事务会有不同的read-view**。如图中看到的，在视图A、B、C里面，这一个记录的值分别是1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于read-view A，要得到1，就必须将当前值依次执行图中所有的回滚操作得到。

同时你会发现，即使现在有另外一个事务正在将4改成5，这个事务跟read-view A、B、C对应的事务是不会冲突的。

你一定会问，回滚日志总不能一直保留吧，什么时候删除呢？答案是，在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。

什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的read-view的时候。

基于上面的说明，我们来讨论一下为什么建议你尽量不要使用长事务。

长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。

在MySQL 5.5及以前的版本，回滚日志是跟数据字典一起放在ibdata文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。我见过数据只有20GB，而回滚段有200GB的库。最终只好为了清理回滚段，重建整个库。

除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库，这个我们会在后面讲锁的时候展开。



# 事务的启动方式

begin/start transaction **命令并不是一个事务的起点**，在执行到它们之后的**第一个操作InnoDB表的语句（第一个快照读语句）**，事务才真正启动。如果你想要马上启动一个事务，可以使用start transaction with consistent snapshot 这个命令。



如前面所述，**长事务有这些潜在风险**，我当然是建议你尽量避免。其实很多时候业务开发同学并不是有意使用长事务，通常是由于误用所致。MySQL的事务启动方式有以下几种：

1. 显式启动事务语句， **begin 或 start transaction。配套的提交语句是commit，回滚语句是rollback。**
2. set autocommit=0，这个命令会将这个线程的自动提交关掉。**意味着如果你只执行一个select语句，这个事务就启动了**，而且并不会自动提交。这个事务持续存在直到你主动执行commit 或 rollback 语句，或者断开连接。

有些客户端连接框架会默认连接成功后先执行一个set autocommit=0的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。

因此，**我会建议你总是使用set autocommit=1, 通过显式语句的方式来启动事务。**

但是有的开发同学会纠结“多一次交互”的问题。对于一个需要频繁使用事务的业务，第二种方式每个事务在开始时都不需要主动执行一次 “begin”，减少了语句的交互次数。如果你也有这个顾虑，我建议你使用commit work and chain语法。

在autocommit为1的情况下，用begin显式启动的事务，如果执行commit则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行begin语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。

你可以在information_schema库**的innodb_trx这个表中查询长事务**，比如下面这个语句，用于查找持续时间超过60s的事务。

`select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60`



**在MySQL里，有两个“视图”的概念**：

- 一个是view。它是一个用查询语句定义的**虚拟表**，在调用的时候执行查询语句并生成结果。创建视图的语法是create view ... ，而它的查询方法与表一样。

- 另一个是InnoDB在实现MVCC时用到的**一致性读视图**，即consistent read view，**用于支持RC（Read Committed，读提交）和RR（Repeatable Read，可重复读）**隔离级别的实现。它没有**物理结构**，作用是事务执行期间用来定义“我能看到什么数据”。

  

# “快照”在MVCC里是怎么工作的？

在**可重复读隔离级别下**，事务在启动的时候就“**拍了个快照”**。注意，这个**快照是基于整库的**。

这时，你会说这看上去不太现实啊。如果一个库有100G，那么我启动一个事务，MySQL就要拷贝100G的数据出来，这个过程得多慢啊。可是，我平时的事务执行起来很快啊。

实际上，我们并不需要拷贝出这100G的数据。我们先来看看这个快照是怎么实现的。

InnoDB里面每个**事务有一个唯一的事务ID**，叫作transaction id。它是在**事务开始的时候向InnoDB的事务系统申请的**，是按申请**顺序严格递增的**。

而**每行数据也都是有多个版本的**。每次事务更新数据的时候，都会生成一个**新的数据版本**，并且把transaction id**赋值给这个数据版本的事务ID**，**记为row trx_id**。同时，**旧的数据版本要保留**，并且在新的数据版本中，能够有信息可以直接拿到它。(**数据链**)

也就是说，数据表中的一行记录，其实可能有多个版本(row)，每个版本有自己的row trx_id。

如图2所示，就是一个记录被多个事务连续更新后的状态。

<img src="..\images\68d08d277a6f7926a41cc5541d3dfced.png" style="zoom:50%;" />

图中虚线框里是同一行数据的4个版本，当前最新版本是V4，k的值是22，它是被transaction id 为25的事务更新的，因此它的row trx_id也是25。

你可能会问，前面的文章不是说，语句更新会生成undo log（回滚日志）吗？那么，**undo log在哪呢？**

实际上，图2中的三个虚线箭头，**就是undo log；**而V1、V2、V3并不是物理上真实存在的，**而是每次需要的时候根据当前版本和undo log计算出来的**。比如，需要V2的时候，就是通过V4依次执行U3、U2算出来。

明白了多版本和row trx_id的概念后，我们再来想一下，InnoDB是怎么定义那个“100G”的快照的。

按照可重复读的定义，**一个事务启动的时候**，**能够看到所有已经提交的事务结果**。但是之后，这个事务执行期间，其他事务的更新对它不可见。

因此，一个事务只需要在启动的时候声明说，**“以我启动的时刻为准，如果一个数据版本是在我启动之前生成的**，就认；如果是我启动以后才生成的，**我就不认，我必须要找到它的上一个版本**”。

当然，如果“上一个版本”也不可见，那就得继续往前找。还有，如果是这个事务自己更新的数据，它自己还是要认的。

在实现上， InnoDB为每个事务构造了一个数组，用来保存这个事务启动瞬间，**当前正在“活跃”的所有事务ID。“活跃”指的就是，启动了但还没提交**。

数组里面事务ID的**最小值记为低水位**，**当前系统里面已经创建过的事务ID的最大值加1记为高水位**。

这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。

而数据版本的可见性规则，就是基于数据的row trx_id和这个一致性视图的对比结果得到的。

这个视图数组把所有的row trx_id 分成了几种不同的情况。

<img src="..\images\882114aaf55861832b4270d44507695e.png" style="zoom:43%;" />

这样，对于**当前事务的启动瞬间来说**，一个数据版本的row trx_id，有以下几种可能：

1. 如果落在绿色部分，表示这个**版本是已提交的事务或者是当前事务自己生成的**，**这个数据是可见的**；
2. 如果落在红色部分，表示这个版本是**由将来启动的事务生成的，是肯定不可见的**；
3. 如果落在黄色部分，那就包括两种情况
   a. 若 row trx_id在数组中，表示这个版本是由**还没提交的事务生成的**，不可见；
   b. 若 row trx_id不在数组中，表示这个版本是已经提交了的事务生成的，可见。

1. 版本未提交，不可见；
2. 版本已提交，**但是是在视图创建后提交的**，不可见；
3. 版本已提交，**而且是在视图创建前提交的，可见**。

**更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。**

因此，在更新的时候，当前读拿到的数据是(1,2)，更新后生成了新版本的数据(1,3)，这个新版本的row trx_id是101。

所以，在执行事务B查询语句的时候，一看自己的版本号是101，最新数据的版本号也是101，是自己的更新，可以直接使用，所以查询得到的k的值是3。



叫作当前读。其实，除了update语句外，**select语句如果加锁，也是当前读。**



而事务**更新数据的时候**，只能用当前读。如果当**前的记录的行锁被其他事务占用的话，**就需要进入锁等待。







而**读提交的逻辑和可重复读的逻辑类似**，它们最主要的区别是：

- 在**可重复读隔离级别下**，只需要在**事务开始**的时候创建**一致性视图**，之后事务里的其他查询**都共用这个一致性视图**；
- 在读提交隔离级别下，**每一个语句执行前都会重新算出一个新的视图**。





# 小结

InnoDB的行数据有多个版本，**每个数据版本有自己的row trx_id**，每个事务或者语句有自己的一致性视图。普通查询语句是一致性读，一致性读会根据row trx_id和一致性视图确定数据版本的可见性。

- 对于可重复读，查询只承认在**事务启动前就已经提交完成的数据**；
- 对于读提交，查询只承认在
- 就已经提交完成的数据；























在Innodb中，**每次开启一个事务时，都会为该session分配一个事务对象**。而为了对全局所有的事务进行控制和协调，有一个全局对象trx_sys，对trx_sys相关成员的操作需要trx_sys->mutex锁。



Innodb使用一种称做**ReadView(视图)的对象来判断事务的可见性（也就是ACID中的隔离性）**。根据可见性原则，某个新开启的事务不应该看到其他未提交的事务。 Innodb在执行一个SELECT或者显式开启START TRANSACTION WITH CONSISTENT SNAPSHOT (后者只应用于REPEATABLE-READ隔离级别) 会创建一个视图对象。对于RR隔离级别，视图的生命周期到事务提交结束，对于RC隔离级别，则每条查询开始时重分配事务。**（应该是begin后第一句select语句开始）**



**那么如何判断可见性呢**？ 对于聚集索引，**每次修改记录时，都会在记录中保存当前的事务ID**，同时旧版本记录存储在UNDO中；对于二级索引，则在二级索引页中存储了更新当前页的最大事务ID，如果该事务ID大于readview->up_limit_id（对于上例，up_limit_id值为2），那么就需要回聚集索引判断记录可见性；如果小于2， 那么总是可见的，可以直接读取。

Innodb的多版本数据使用UNDO来维护的，例如聚集索引记录(1) =>(2)=>(3)，从1更新成2，再更新成3，就会产生两条undo记录。当然这不是本文讨论的重点。后续在单独针对临时表的优化时会谈及undo相关的知识。





***事务ACID:\***

 **原子性**，**指的是整个事务要么全部成功，要么全部失败**，对InnoDB来说，只要client收到server发送过来的commit成功报文，那么这个事务一定是成功的。如果收到的是rollback的成功报文，那么整个事务的所有操作一定都要被回滚掉，就好像什么都没执行过一样。另外，如果连接中途断开或者server crash事务也要保证会滚掉。**InnoDB通过undolog保证rollback的时候能找到之前的数据**。

**一致性**，指的是在任何时刻，**包括数据库正常提供服务的时候，数据库从异常中恢复过来的时候，数据都是一致的**，**保证不会读到中间状态的数据**。在InnoDB中，**主要通过crash recovery和double write buffer的机制保证数据的一致性**。

**隔离性**，指的是多个事务可以同时对数据进行修改，但是相互不影响。InnoDB中，依据不同的业务场景，有四种隔离级别可以选择。默认是RR隔离级别，因为相比于RC，InnoDB的RR性能更加好。

**持久性**，值的是事务commit的数据在任何情况下都不能丢。在内部实现中，InnoDB通过redolog保证已经commit的数据一定不会丢失。





***多版本控制:\*** 指的是一种**提高并发的技术**。最早的数据库系统，**只有读读之间可以并发**，读写，写读，写写都要阻塞。引入多版本之后，**只有写写之间相互阻塞**，其他三种操作都可以并行，这样大幅度提高了InnoDB的并发度。在内部实现中，与Postgres在数据行上实现多版本不同，**InnoDB是在undolog中实现的，通过undolog可以找回数据的历史版本。找回的数据历史版本可以提供给用户读(按照隔离级别的定义，有些读请求只能看到比较老的数据版本)**，也可以在回滚的时候覆盖数据页上的数据。在InnoDB内部中，会记录一个全局的活跃读写事务数组，其主要用来判断事务的可见性。



***垃圾清理:\*** 对于用户删除的数据，InnoDB并不是立刻删除，**而是标记一下，后台线程批量的真正删除**。类似的还有InnoDB的二级索引的更新操作，**不是直接对索引进行更新，而是标记一下，然后产生一条新的。这个线程就是后台的Purge线程**。此外，过期的undolog也需要回收，这里说的过期**，指的是undo不需要被用来构建之前的版本，也不需要用来回滚事务**



***回滚段:\*** 可以理解为**数据页的修改链**，**链表最前面的是最老的一次修改**，最后面的最新的一次修改，从**链表尾部逆向操作可以恢复到数据最老的版本**。在InnoDB中，与之相关的还有undo tablespace, undo segment, undo slot, undo log这几个概念。undo log是最小的粒度，所在的数据页称为undo page，然后若干个undo page构成一个undo slot。一个事务最多可以有两个undo slot，一个是insert undo slot, 用来存储这个事务的insert undo，里面主要记录了主键的信息，方便在回滚的时候快速找到这一行。另外一个是update undo slot，用来存储这个事务delete/update产生的undo，里面详细记录了被修改之前每一列的信息，便于在读请求需要的时候构造。1024个undo slot构成了一个undo segment。然后若干个undo segemnt构成了undo tablespace。



***历史链表:\*** insert undo可以在事务提交/回滚后直接删除，没有事务会要求查询新插入数据的历史版本，但是update undo则不可以，因为其他读请求可能需要使用update undo构建之前的历史版本。因此，在事务提交的时候，会把update undo加入到一个全局链表(`history list`)中，链表按照事务提交的顺序排序，保证最先提交的事务的update undo在前面，这样Purge线程就可以从最老的事务开始做清理。这个链表如果太长说明有很多记录没被彻底删除，也有很多undolog没有被清理，这个时候就需要去看一下是否有个长事务没提交导致Purge线程无法工作。在InnoDB具体实现上，history list其实只是undo segment维度的，全局的history list采用最小堆来实现，最小堆的元素是某个undo segment中最小事务no对应的undopage。当这个undolog被Purge清理后，通过history list找到次小的，然后替换掉最小堆元素中的值，来保证下次Purge的顺序的正确性。

***回滚点:\*** 又称为savepoint，事务回滚的时候可以指定回滚点，这样可以保证回滚到指定的点，而不是回滚掉整个事务，对开发者来说，这是一个强大的功能。在InnoDB内部实现中，每打一个回滚点，其实就是保存一下当前的undo_no，回滚的时候直接回滚到这个undo_no点就可以了。







***trx_t:\*** 整个结构体每个连接持有一个，也就是在创建连接后执行第一个事务开始，整个结构体就被初始化了，后续这个连接的所有事务一直复用里面的数据结构，直到这个连接断开。同时，事务启动后，就会把这个结构体加入到全局事务链表中(`trx_sys->mysql_trx_list`)，如果是读写事务，还会加入到全局读写事务链表中(`trx_sys->rw_trx_list`)。在事务提交的时候，还会加入到全局提交事务链表中(`trx_sys->trx_serial_list`)。state字段记录了事务四种状态:`TRX_STATE_NOT_STARTED`, `TRX_STATE_ACTIVE`, `TRX_STATE_PREPARED`, `TRX_STATE_COMMITTED_IN_MEMORY`。 这里有两个字段值得区分一下，分别是id和no字段。id是在事务刚创建的时候分配的(只读事务永远为0，读写事务通过一个全局id产生器产生，非0)，目的就是为了区分不同的事务(只读事务通过指针地址来区分)，而no字段是在事务提交前，通过同一个全局id生产器产生的，主要目的是为了确定事务提交的顺序，保证加入到`history list`中的update undo有序，方便purge线程清理。 此外，trx_t结构体中还有自己的read_view用来表示当前事务的可见范围。分配的insert undo slot和update undo slot。如果是只读事务，read_only也会被标记为true。



***read_view_t:\*** InnDB为了判断某条记录是否对当前事务可见，需要对此记录进行可见性判断，这个结构体就是用来辅助判断的。每个连接都的trx_t里面都有一个readview，在事务需要一致性的读时候(不同隔离级别不同)，会被初始化，在读结束的时候会释放(缓存)。low_limit_no，这个主要是给purge线程用，readview创建的时候，会把当前最小的提交事务id赋值给low_limit_no，这样Purge线程就可以把所有已经提交的事务的undo日志给删除。low_limit_id, 所有大于等于此值的记录都不应该被此readview看到，可以理解为high water mark。up_limit_id, 所有小于此值的记录都应该被此readview看到，可以理解为low water mark。descriptors, 这是一个数组，里面存了readview创建时候所有全局读写事务的id，除了事务自己做的变更外，此readview应该看不到descriptors中事务所做的变更。view_list，每个readview都会被加入到trx_sys中的全局readview链表中。



***trx_id_t:\*** 每个读写事务都会通过全局id产生器产生一个id，只读事务的事务id为0，只有当其切换为读写事务时候再分配事务id。为了保证在任何情况下(包括数据库不断异常恢复)，事务id都不重复，InnoDB的全局id产生器每分配256(`TRX_SYS_TRX_ID_WRITE_MARGIN`)个事务id，就会把当前的max_trx_id持久化到ibdata的系统页上面。此外，每次数据库重启，都从系统页上读取，然后加上256(`TRX_SYS_TRX_ID_WRITE_MARGIN`)。



## 事务的启动

在InnoDB里面有两种事务，**一种是读写事务**，就是会对数据进行修改的事务，**另外一种是只读事务**，仅仅对数据进行读取。读写事务需要比只读事务多做以下几点工作：**首先，需要分配回滚段，因为会修改数据，就需要找地方把老版本的数据给记录下来**，其次，需要通过全局事务id产生器产生一个事务id，最后，把读写事务加入到全局读写事务链表(`trx_sys->rw_trx_list`)，把事务id加入到活跃读写事务数组中(`trx_sys->descriptors`)。因此，可以看出，读写事务确实需要比只读事务多做不少工作，在使用数据库的时候尽可能把事务申明为只读。



`start transaction`语句启动事务。这种语句和`begin work`,`begin`等效。这些语句默认是以只读事务的方式启动。`start transaction read only`语句启动事务。这种语句就把`thd->tx_read_only`置为true，后续如果做了DML/DDL等修改数据的语句，会返回错误`ER_CANT_EXECUTE_IN_READ_ONLY_TRANSACTION`。`start transaction read write`语句启动事务。这种语句会把`thd->tx_read_only`置为true，此外，允许super用户在read_only参数为true的情况下启动读写事务。`start transaction with consistent snapshot`语句启动事务。这种启动方式还会进入InnoDB层，并开启一个readview。注意，只有在RR隔离级别下，这种操作才有效，否则会报错。

上述的几种启动方式，都会先去检查前一个事务是否已经提交，如果没有则先提交，然后释放MDL锁。此外，除了`with consistent snapshot`的方式会进入InnoDB层，其他所有的方式都只是在Server层做个标记，没有进入InnoDB做标记，在InnoDB看来所有的事务在启动时候都是只读状态，只有接受到修改数据的SQL后(InnoDB接收到才行。因为在`start transaction read only`模式下，DML/DDL都被Serve层挡掉了)才调用`trx_set_rw_mode`函数把只读事务提升为读写事务。 新建一个连接后，在开始第一个事务前，在InnoDB层会调用函数`innobase_trx_allocate`分配和初始化trx_t对象。默认的隔离级别为REPEATABLE_READ，并且加入到`mysql_trx_list`中。注意这一步仅仅是初始化trx_t对象，但是真正开始事务的是函数`trx_start_low`，在`trx_start_low`中，如果当前的语句只是一条只读语句，则先以只读事务的形式开启事务，否则按照读写事务的形式，这就需要分配事务id，分配回滚段等。



## 事务的提交

相比于事务的启动，事务的提交就复杂许多。这里只介绍事务在InnoDB层的提交过程，Server层涉及到与Binlog的XA事务暂时不介绍。入口函数为`innobase_commit`。

函数有一个参数`commit_trx`来控制是否真的提交，因为每条语句执行结束的时候都会调用这个函数，而不是每条语句执行结束的时候事务都提交。如果这个参数为true，或者配置了`autocommit=1`, 则进入提交的核心逻辑。否则释放因为auto_inc而造成的表锁，并且记录undo_no(回滚单条语句的时候用到，相关参数`innodb_rollback_on_timeout`)。 提交的核心逻辑：



1. 依据参数innobase_commit_concurrency来判断是否有过多的线程同时提交，如果太多则等待。
2. 设置事务状态为committing，我们可以在`show processlist`看到(`trx_commit_for_mysql`)。
3. 使用全局事务id产生器生成事务no，然后把事务trx_t加入到`trx_serial_list`。如果当前的undo segment没有设置最后一个未Purge的undo，则用此事务no更新(`trx_serialisation_number_get`)。
4. 标记undo，如果这个事务只使用了一个undopage且使用量小于四分之三个page，则把这个page标记为(`TRX_UNDO_CACHED`)。如果不满足且是insert undo则标记为`TRX_UNDO_TO_FREE`，否则undo为update undo则标记为`TRX_UNDO_TO_PURGE`。标记为`TRX_UNDO_CACHED`的undo会被回收，方便下次重新利用(`trx_undo_set_state_at_finish`)。
5. 把update undo放入所在undo segment的history list，并递增`trx_sys->rseg_history_len`(这个值是全局的)。同时更新page上的`TRX_UNDO_TRX_NO`, 如果删除了数据，则重置delete_mark(`trx_purge_add_update_undo_to_history`)。
6. 把undate undo从update_undo_list中删除，如果被标记为`TRX_UNDO_CACHED`，则加入到update_undo_cached队列中(`trx_undo_update_cleanup`)。
7. 在系统页中更新binlog名字和偏移量(`trx_write_serialisation_history`)。
8. mtr_commit，至此，在文件层次事务提交。这个时候即使crash，重启后依然能保证事务是被提交的。接下来要做的是内存数据状态的更新(`trx_commit_in_memory`)。
9. 如果是只读事务，则只需要把readview从全局readview链表中移除，然后重置trx_t结构体里面的信息即可。如果是读写事务，情况则复杂点，首先需要是设置事务状态为`TRX_STATE_COMMITTED_IN_MEMORY`，其次，释放所有行锁，接着，trx_t从rw_trx_list中移除，readview从全局readview链表中移除，另外如果有insert undo则在这里移除(update undo在事务提交前就被移除，主要是为了保证添加到history list的顺序)，如果有update undo，则唤醒Purge线程进行垃圾清理，最后重置trx_t里的信息，便于下一个事务使用。



#### 事务的回滚

InnoDB的事务回滚是通过**undolog来逆向操作来实现的**，但是undolog是存在undopage中，undopage跟普通的数据页一样，遵循bufferpool的淘汰机制，**如果一个事务中的很多undopage已经被淘汰出内存了，那么在回滚的时候需要重新把这些undopage从磁盘中捞上来，这会造成大量io**，需要注意。此外，由于引入了savepoint的概念，事务不仅可以全部回滚，也可以回滚到某个指定点。

回滚的上层函数是`innobase_rollback_trx`，主要流程如下：

1. 如果是只读事务，则直接返回。
2. 判断当前是回滚整个事务还是部分事务，如果是部分事务，则记录下需要保留多少个undolog，多余的都回滚掉，如果是全部回滚，则记录0(trx_rollback_step)。
3. 从update undo和insert undo中找出最后一条undo，从这条undo开始回滚(`trx_roll_pop_top_rec_of_trx`)。
4. 如果是update undo则调用`row_undo_mod`进行回滚，标记删除的记录清理标记，更新过的数据回滚到最老的版本。如果是insert undo则调用`row_undo_ins`进行回滚，插入操作，直接删除聚集索引和二级索引。
5. 如果是在奔溃恢复阶段且需要回滚的undolog个数大于1000条，则输出进度。
6. 如果所有undo都已经被回滚或者回滚到了指定的undo，则停止，并且调用函数`trx_roll_try_truncate`把undolog删除(由于不需要使用unod构建历史版本，所以不需要留给Purge线程)。 此外，需要注意的是，回滚的代码由于是嵌入在query graphy的框架中，因此有些入口函数不太好找。例如，确定回滚范围的是在函数`trx_rollback_step`中，真正回滚的操作是在函数`row_undo_step`中，两者都是在函数`que_thr_step`被调用。



## 多版本控制MVCC

数据库需要做好版本控制，**防止不该被事务看到的数据(例如还没提交的事务修改的数据)被看到**。在InnoDB中，**主要是通过使用readview的技术来实现判断。查询出来的每一行记录**，**都会用readview来判断一下当前这行是否可以被当前事务看到，如果可以，则输出，否则就利用undolog来构建历史版本**，再进行判断，知道记录构建到最老的版本或者可见性条件满足。

在trx_sys中，一直维护这一个全局的活跃的读写事务id(`trx_sys->descriptors`)，id按照从小到大排序，表示在某个时间点，数据库中所有的活跃(已经开始但还没提交)的读写(必须是读写事务，只读事务不包含在内)事务。当需要一个一致性读的时候(即创建新的readview时)，会把全局读写事务id拷贝一份到readview本地(read_view_t->descriptors)，当做当前事务的快照。read_view_t->up_limit_id是read_view_t->descriptors这数组中最小的值，read_view_t->low_limit_id是创建readview时的max_trx_id，即一定大于read_view_t->descriptors中的最大值。当查询出一条记录后(记录上有一个trx_id，表示这条记录最后被修改时的事务id)，可见性判断的逻辑如下(`lock_clust_rec_cons_read_sees`)：

如果记录上的trx_id小于read_view_t->up_limit_id，则说明这条记录的最后修改在readview创建之前，因此这条记录可以被看见。

如果记录上的trx_id大于等于read_view_t->low_limit_id，则说明这条记录的最后修改在readview创建之后，因此这条记录肯定不可以被看家。

如果记录上的trx_id在up_limit_id和low_limit_id之间，且trx_id在read_view_t->descriptors之中，则表示这条记录的最后修改是在readview创建之时，被另外一个活跃事务所修改，所以这条记录也不可以被看见。如果trx_id不在read_view_t->descriptors之中，则表示这条记录的最后修改在readview创建之前，所以可以看到。

**基于上述判断，如果记录不可见，则尝试使用undo去构建老的版本(`row_vers_build_for_consistent_read`)，直到找到可以被看见的记录或者解析完所有的undo。**

针对RR隔离级别，在第一次创建readview后，**这个readview就会一直持续到事务结束，也就是说在事务执行过程中，数据的可见性不会变，所以在事务内部不会出现不一致的情况**。针对RC隔离级别，**事务中的每个查询语句都单独构建一个readview，所以如果两个查询之间有事务提交了**，两个查询读出来的结果就不一样。从这里可以看出，在InnoDB中，RR隔离级别的效率是比RC隔离级别的高。此外，针对RU隔离级别，由于不会去检查可见性，所以在一条SQL中也会读到不一致的数据。针对串行化隔离级别，InnoDB是通过锁机制来实现的，而不是通过多版本控制的机制，所以性能很差。

由于readview的创建涉及到拷贝全局活跃读写事务id，所以需要加上trx_sys->mutex这把大锁，为了减少其对性能的影响，关于readview有很多优化。例如，如果前后两个查询之间，没有产生新的读写事务，那么前一个查询创建的readview是可以被后一个查询复用的。

## 垃圾回收Purge线程

Purge线程主要做两件事，第一，数据页内标记的删除操作需要从物理上删除，为了提高删除效率和空间利用率，由后台Purge线程解析undolog定期批量清理。第二，当数据页上标记的删除记录已经被物理删除，同时undo所对应的记录已经能被所有事务看到，这个时候undo就没有存在的必要了，因此Purge线程还会把这些undo给truncate掉，释放更多的空间。

Purge线程有两种，一种是Purge Worker(`srv_worker_thread`), 另外一种是Purge Coordinator(`srv_purge_coordinator_thread`)，前者的主要工作就是从队列中取出Purge任务，然后清理已经被标记的记录。后者的工作除了清理删除记录外，还需要把Purge任务放入队列，唤醒Purge Worker线程，此外，它还要truncate undolog。

我们先来分析一下Purge Coordinator的流程。启动线程后，会进入一个大的循环，循环的终止条件是数据库关闭。在循环内部，首先是自适应的sleep，然后才会进入核心Purge逻辑。sleep时间与全局历史链表有关系，如果历史链表没有增长，且总数小于5000，则进入sleep，等待事务提交的时候被唤醒(`srv_purge_coordinator_suspend`)。退出循环后，也就是数据库进入关闭的流程，这个时候就需要依据参数innodb_fast_shutdown来确定在关闭前是否需要把所有记录给清除。接下来，介绍一下核心Purge逻辑。

1. 首先依据当前的系统负载来确定需要使用的Purge线程数(`srv_do_purge`)，即如果压力小，只用一个Purge Cooridinator线程就可以了。如果压力大，就多唤醒几个线程一起做清理记录的操作。如果全局历史链表在增加，或者全局历史链表已经超过`innodb_max_purge_lag`，则认为压力大，需要增加处理的线程数。如果数据库处于不活跃状态(`srv_check_activity`)，则减少处理的线程数。
2. 如果历史链表很长，超过`innodb_max_purge_lag`，则需要重新计算delay时间(不超过`innodb_max_purge_lag_delay`)。如果计算结果大于0，则在后续的DML中需要先sleep，保证不会太快产生undo(`row_mysql_delay_if_needed`)。
3. 从全局视图链表中，克隆最老的readview，所有在这个readview开启之前提交的事务所产生的undo都被认为是可以清理的。克隆之后，还需要把最老视图的创建者的id加入到`view->descriptors`中，因为这个事务修改产生的undo，暂时还不能删除(`read_view_purge_open`)。
4. 从undo segment的最小堆中，找出最早提交事务的undolog(`trx_purge_get_rseg_with_min_trx_id`)，如果undolog标记过delete_mark(表示有记录删除操作)，则把先关undopage信息暂存在purge_sys_t中(`trx_purge_read_undo_rec`)。
5. 依据purge_sys_t中的信息，读取出相应的undo，同时把相关信息加入到任务队列中。同时更新扫描过的指针，方便后续truncate undolog。
6. 循环第4步和第5步，直到全局历史链表为空，或者接下到view->low_limit_no，即最老视图创建时已经提交的事务，或者已经解析的page数量超过`innodb_purge_batch_size`。
7. 把所有的任务都放入队列后，就可以通知所有Purge Worker线程(如果有的话)去执行记录删除操作了。删除记录的核心逻辑在函数`row_purge_record_func`中。有两种情况，一种是数据记录被删除了，那么需要删除所有的聚集索引和二级索引(`row_purge_del_mark`)，另外一种是二级索引被更新了(总是先删除+插入新记录)，所以需要去执行清理操作。
8. 在所有提交的任务都已经被执行完后，就可以调用函数`trx_purge_truncate`去删除update undo(insert undo在事务提交后就被清理了)。每个undo segment分别清理，从自己的histrory list中取出最早的一个undo，进行truncate(`trx_purge_truncate_rseg_history`)。truncate中，最终会调用`fseg_free_page`来清理磁盘上的空间。











| **级别** | **symbol**       | 值   | **描述**                                                     |
| -------- | ---------------- | ---- | ------------------------------------------------------------ |
| 读未提交 | READ-UNCOMMITTED | 0    | 存在脏读、不可重复读、幻读的问题                             |
| 读已提交 | READ-COMMITTED   | 1    | 解决脏读的问题，存在不可重复读、幻读的问题                   |
| 可重复读 | REPEATABLE-READ  | 2    | mysql 默认级别，解决脏读、不可重复读的问题，存在幻读的问题。使用 MMVC机制 实现可重复读 |
| 序列化   | SERIALIZABLE     | 3    | 解决脏读、不可重复读、幻读，可保证事务安全，但完全串行执行，性能最低 |



```
SELECT @@global.tx_isolation, @@tx_isolation;
SET @@gloabl.tx_isolation = 0;
SET @@gloabl.tx_isolation = 'READ-UNCOMMITTED';
```



#### 幻读

幻读会在 RU / RC / RR 级别下出现，SERIALIZABLE 则杜绝了幻读，但 RU / RC 下还会存在脏读，不可重复读，故我们就以 RR 级别来研究幻读，排除其他干扰。

注意：RR 级别下存在幻读的可能，**但也是可以使用对记录手动加 X锁 的方法消除幻读**。SERIALIZABLE 正是对所有事务都加 X锁 才杜绝了幻读，但很多场景下我们的业务sql并不会存在幻读的风险。SERIALIZABLE 的一刀切虽然事务绝对安全，但性能会有很多不必要的损失。故可以在 RR 下根据业务需求决定是否加锁，存在幻读风险我们加锁，不存在就不加锁，事务安全与性能兼备，这也是 RR 作为mysql默认隔是个事务离级别的原因，所以需要正确的理解幻读。

*幻读错误的理解：说幻读是 事务A 执行两次 select 操作得到不同的数据集，即 select 1 得到 10 条记录，select 2 得到 11 条记录。这其实并不是幻读，这是不可重复读的一种，只会在 R-U R-C 级别下出现，**而在 mysql 默认的 RR 隔离级别是不会出现的**。*

幻读，**并不是说两次读取获取的结果集不同**，幻读侧重的方面是某一次的 select **操作得到的结果所表征的数据状态无法支撑后续的业务操作**。更为具体一些：**select 某记录是否存在，不存在，准备插入此记录，但执行 insert 时发现此记录已存在**，**无法插入，此时就发生了幻读。**



其实 RR 也是可以避免幻读的，**通过对 select 操作手动加 行X锁（**SELECT ... FOR UPDATE 这也正是 SERIALIZABLE 隔离级别下会隐式为你做的事情），同时还需要知道，即便当前记录不存在，比如 id = 1 是不存在的，当前事务也会获得一把记录锁（因为InnoDB的行锁锁定的是索引，故记录实体存在与否没关系，存在就加 行X锁，不存在就加 next-key lock间隙X锁），其他事务则无法插入此索引的记录，故杜绝了幻读。



所以 mysql 的**幻读并非什么读取两次返回结果集不同**，而是事务在插入事先检测不存在的记录时，惊奇的发现这些数据已经存在了，之前的检测读获取到的数据如同鬼影一般。



```
# 这里需要用 X锁， 用 LOCK IN SHARE MODE 拿到 S锁 后我们没办法做写操作
SELECT `id` FROM `users` WHERE `id` = 1 FOR UPDATE;
```

如果 id = 1 的记录存在则会被加**行（X）锁**，如果不存在，**则会加 next-lock key / gap 锁（范围行锁）**，即记录存在与否，mysql 都会对记录应该对应的索引加锁，其他事务是无法再获得做操作的。